{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Домашнее задание №3 (курс \"Практикум по программированию на языке Python\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тема: Основы анализа данных и машинного обучения в Python.\n",
    "\n",
    "#### Преподаватель: Мурат Апишев (mel-lain@yandex.ru)\n",
    "\n",
    "**Выдана**:   14 апреля 2020\n",
    "\n",
    "**Дедлайн**:   21:00 28 апреля 2020\n",
    "\n",
    "**Среда выполнения**: Jupyter Notebook (Python 3.7)\n",
    "\n",
    "#### Правила:\n",
    "\n",
    "Результат выполнения задания - Jupyter Notebook с кодом и подробными ответами в случае теоретических вопросов. __Максимальное число баллов за задание - 20__.\n",
    "\n",
    "Все ячейки должны быть \"выполненными\", при этом результат должен воспроизводиться при проверке (на Python 3.7). Если какой-то код не был запущен или отрабатывает с ошибками, то пункт не засчитывается. Задание, сданное после дедлайна, _не принимается_. Можно отправить недоделанное задание, выполненные пункты будут оценены.\n",
    "\n",
    "Готовое задание отправляется на почту преподавателя.\n",
    "\n",
    "Задание выполняется самостоятельно. Если какие-то студенты будут уличены в списывании, все они автоматически получат за эту работу 0 баллов. Если вы нашли в Интернете какой-то специфичный код, который собираетесь заимствовать, обязательно укажите это в задании - наверняка вы не единственный, кто найдёт и использует эту информацию.\n",
    "\n",
    "Удалять фрагменты формулировок заданий запрещается."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Постановка задачи:\n",
    "\n",
    "- В данной работе нужно решить ряд задач c использованиеv библиотек `numpy`, `pandas`, `sklearn` и `matplotlib`, а также дать ичерпывающие ответы на поставленные вопросы.\n",
    "- В задачах 1-3 запрещается использовать циклы, генераторы списков и списковые включения, а также функции высшего порядка, необходимо написать тесты, проверяющие работу решения в обычных и крайних случаях.\n",
    "- Даже если это не указано явно в требованиях, код должен быть по возможности неизбыточным, работать с разумной сложностью и объёмом потребялемой памяти, проверяющие могут снизить балл за задание, выполненное без учёта этого требования.\n",
    "- Результирующий код должен быть читаемым, с единой системой отступов и адеквантными названиями переменных, проверяющие могут снизить балл за задание, выполненное без учёта этого требования."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 1 (0.5 балла):__ Проверить, что все элементы входного массива строго положительны."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_1(arr):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 2 (0.5 балла):__ В векторе повторить все значения `n` раз. Пример: для массива `[1, 2, 3]` и `n` равного 3 ответом должен быть массив `[1, 1, 1, 2, 2, 2, 3, 3, 3]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_2(arr, n):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 3 (1 балл):__ Для векторов `V` и `v` построить вектор, в котором на 0-й позиции будет находиться сумма первых `v[0]` элементов вектора `V`, на 1-й - следующих `v[1]` элементов, и т.д. Гарантируется, что элементов в `V` достаточное количество. Пример: для массивов `V=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]` и `v=[2, 1, 3]` ответом будет `[3, 3, 15]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_3(V, v ):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для следующих нескольких заданий потребуются данные. Скачайте датасет, описывающий различные автомобили, из [репозитория UCI](https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/vehicle/).\n",
    "\n",
    "Соберите из `.dat` файлов один файл `car_data.csv`, который и будет использоваться далее. Будем решать задачу многоклассовой классификации, Везде, где это требуется, используйте подход One-vs-Rest.\n",
    "\n",
    "Запустите следующий код на полученном файле с данными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset = pd.read_csv('car_data.csv', delimiter=',', header=None).values\n",
    "data = dataset[:, :-1].astype(int)\n",
    "target = dataset[:, -1]\n",
    "\n",
    "print(data.shape, target.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.35)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 4 (1.5 балла):__ Воспользуйтесь возможностями библиотеки pandas для того, чтобы произвести базовый анализ данных. Обоснованно ответьте на следующие вопросы/решите задачи:\n",
    "\n",
    "- сколько признаков в данных, каких они типов?\n",
    "- имеются ли пропущенные значения?\n",
    "- для каждого числового признака посчитайте его среднее значение и стандартное отклонение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 5 (1 балл):__ Произведите необходимые (по вашему мнению) манипуляции с данными и объясните их."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 6 (2.5 балла):__ Подберите оптимальные параметры логистической регресии с помощью кросс-валидации на train-датасете (не переусердствуйте с подбором, в данной работе не стоит задача найти самую оптимальную модель. Небольшого grid/random search хватит). Постройте график ROC-кривой для данного классификатора, кривой Precision-Recall, оцените точность классификации и f1-score с разными порогами вероятности отнесения к классу. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 7 (1.5 балла):__ Одним из методов понижения размерности данных является линейное преобразование PCA (метод главных компонент), идея которого заключается в том, чтобы спроецировать выборку на подпространство из тех признаков, по которым значение дисперсии наиболее велико.\n",
    "\n",
    "- Ознакомьтесь с данным методом, затем примените реализацию из `sklearn` к обучающей выборке (train).\n",
    "- Постройте график зависимости объясненной дисперсии (explained variance ratio) от количества главных компонент. \n",
    "- Визуализируйте данные в пространстве первых двух главных компонент."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 8 (0.5 балла):__ Выберите определенное число компонент. Кратко опишите, чем обусловлен ваш выбор. Используя эти главные компоненты, преобразуйте train и test выборки (используя методы `fit` и `transform`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 9 (1 балл):__ Подберите оптимальные параметры логистической регресии с помощью кросс-валидации на преобразованном train-датасете. Постройте график ROC-кривой для полученных классификаторов, кривой Precision-Recall, оцените точность классификации и f1-score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для следующих заданий потребуется синтетическая выборка."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from sklearn.datasets import make_moons\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "moons_points, moons_labels = make_moons(n_samples=500, noise=0.2, random_state=42)\n",
    "plt.scatter(moons_points[:, 0], moons_points[:, 1], c=moons_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 10 (1 балл):__ Попробуйте обучить на этих данных линейный SVM (используйте класс `svm.SVC`), померяйте качество в терминах метрик, рассмотренных выше. Изобразите разделяющую прямую (смотрите примеры в документации `sklearn`). Какие есть проблемы?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 11 (2.5 балл):__ Применим ядровой переход. Попробуйте перебрать различные ядра (полиномиальное, rbf, сигмоидальное) и важные для них гиперпараметры, оптимизируя f1-меру на обучающих данных. Нарисуйте соответствующие графики зависимости качества от значений разных параметров. Для наилучшего набора измерьте/изобразите все описанные в предыдущих заданиях метрики (на тестовой выборке). Изобразите итоговую разделяющую поверхность для лучшего решения на всей выборке.\n",
    "\n",
    "Ответьте на следующие вопросы:\n",
    "- как изменилось качество классификации на тесте?\n",
    "- какая степень полиномиального ядра оказалась лучшей? Почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 12 (1.5 балл):__ Такого рода задачу можно решить и с помощью линейного классификатора, например, лог-регресии. Здесь может помочь генерация нового признакового пространства путём использования полиномиальных признаков (посмотрите класс `PolynomialFeatures` в `sklearn`). Сгенерируйте новые признаки (попробуйте разные степени), обучите на них лог-регрессию и померяйте качество в терминах описанных выше метрик. Какая степень оказалась наилучшей с точки зрения качества на тесте? Сравните с результатами ядрового SVM с полиномиальным ядром с той же степенью."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этой секции мы поработаем с датасетом Human Activity Recognition (HAR). Данные доступны в [репозитории UCI](https://archive.ics.uci.edu/ml/datasets/human+activity+recognition+using+smartphones). Скачайте их и поместите директорию `data` в одной директории с этим ноутбуком. Доступны сырая и предобработанная версии данных, в этой части задания мы будем работать с предобработанными.\n",
    "\n",
    "Выберите одну из библиотек для градиентного бустинга, которой вы воспользуетесь в дальнейшем (если есть желание, можете попробовать все, это полезно):\n",
    "\n",
    "- LightGBM by Microsoft. [Link to github](https://github.com/Microsoft/LightGBM).\n",
    "- xgboost by dlmc. [Link to github](https://github.com/dmlc/xgboost).\n",
    "- Catboost by Yandex. [Link to github](https://github.com/catboost/catboost).\n",
    "\n",
    "Реализацию Random Forest возьмите из `sklearn`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 13 (5 баллов):__ Предобработайте данные, используя информацию с лекций/семинаров, после чего примените к предобработанному датасету случайный лес и градиентный бустинг. Основной задачей является достижение не менее 85% точности классификации на тестовых данных. Детали:\n",
    "\n",
    "- изучите смысл и состав признаков, нет ли признаков, являющихся лишними или вредными? Ответ поясните\n",
    "- вспомните про метод главных компонент, не мог бы он помочь в этой задаче?\n",
    "- для получения нужного качества модели нужно аккуратно настраивать. Процесс настройки (с перебором гиперпараметров по сетке) отобразите в виде графиков зависимости качества от гиперпараметров\n",
    "\n",
    "При выставлении баллов за это задание будет оцениваться как качество решения, так и полнота/корректность опробованных идей и методов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.genfromtxt('data/train/X_train.txt')\n",
    "y_train = np.genfromtxt('data/train/y_train.txt')\n",
    "\n",
    "X_test = np.genfromtxt('data/test/X_test.txt')\n",
    "y_test = np.genfromtxt('data/test/y_test.txt')\n",
    "\n",
    "with open('data/activity_labels.txt', 'r') as iofile:\n",
    "    activity_labels = iofile.readlines()\n",
    "\n",
    "activity_labels = [x.replace('\\n', '').split(' ') for x in activity_labels]\n",
    "activity_labels = dict([(int(x[0]), x[1]) for x in activity_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
